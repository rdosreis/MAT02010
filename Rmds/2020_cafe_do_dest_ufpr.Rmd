---
title: "Estatística e Inferência Causal"
subtitle: "Uma breve introdução"
author: |
  | Rodrigo Citton P. dos Reis
  | `citton.padilha@ufrgs.br`
institute: |
  | \textsc{Universidade Federal do Rio Grande do Sul}
  | \textsc{Instituto de Matemática e Estatística}
  | \textsc{Departamento de Estatística}
date: |
  | Café do DEST - UFPR, 2020
---

# O que é inferência causal?

## O que é inferência causal?

>- A inferência causal é a ciência de __inferir a presença e a magnitude das relações de causa e efeito a partir dos dados__.
>- Como estatísticos, epidemiologistas, sociólogos, etc., e de fato como seres humanos, é algo sobre o qual __sabemos muito__.
>    + Suponha que um estudo encontre uma associação entre a "o pai possuir gravata de seda" e a "mortalidade infantil".
>    + Com base nisso, o governo implementa um programa no qual 5 gravatas de seda são dadas a todos os homens com idade entre 18 e 45 anos, com o objetivo de reduzir a mortalidade infantil.
>- Nós todos concordamos que isso é uma bobagem!
>- Isso porque entendemos a __diferença entre associação e causalidade__.

## O que é inferência causal?

O roteiro da inferência causal consiste em (pelo menos) três etapas:

1. Uma __linguagem formal__ para definir inequivocamente conceitos causais.
    + Desfechos potenciais, contrafactuais, operador $do()$
2. __Suposições causais__ para a __identificação__ dos efeitos causais.
    + __Diagramas causais__ (__DAGs__) são uma ferramenta para exibir nossas suposições causais
3. __Métodos de análise__ (isto é, métodos estatísticos) que podem nos ajudar a tirar conclusões causais mais confiáveis a partir dos dados disponíveis.

# Um pouco de dor de cabeça!

## Um exemplo

- 12 senhoras estão sofrendo de __dor de cabeça__.
- Algumas tomam __aspirina__; outras não.
- Uma hora depois, perguntamos para cada uma delas se a dor de cabeça __sumiu (desapareceu)__.

## Os dados observados

|           | $Z$ (tomou aspirina?) | $R$ (dor de cabeça sumiu?) |
| :-------- | :-------------------: | :------------------------: |
| Mary      |           0           |             0              |
| Anna      |           1           |             0              |
| Emma      |           1           |             1              |
| Elizabeth |           0           |             0              |
| Minnie    |           0           |             1              |
| Margaret  |           1           |             0              |
| Ida       |           1           |             0              |
| Alice     |           0           |             0              |
| Bertha    |           0           |             1              |
| Sarah     |           0           |             0              |
| Annie     |           0           |             1              |
| Clara     |           1           |             1              |

## Os dados observados

|                       | $Z$ (tomou aspirina?) | $R$ (dor de cabeça sumiu?) |
| :-------------------- | :-------------------: | :------------------------: |
| Mary                  |           0           |             0              |
| Anna                  |           1           |             0              |
| \textcolor{red}{Emma} |  \textcolor{red}{1}   |     \textcolor{red}{1}     |
| Elizabeth             |           0           |             0              |
| Minnie                |           0           |             1              |
| Margaret              |           1           |             0              |
| Ida                   |           1           |             0              |
| Alice                 |           0           |             0              |
| Bertha                |           0           |             1              |
| Sarah                 |           0           |             0              |
| Annie                 |           0           |             1              |
| Clara                 |           1           |             1              |

## Os dados observados

- Emma tomou aspirina ($Z = 1$) e a sua dor de cabeça passou ($R = 1$).
- A aspirina __causou__ o desaparecimento da sua dor de cabeça?

## Estrutura

A estrutura da inferência causal:

>- $X_i$ representa um vetor de covariáveis __observadas__: idade, faz uso de medicamentos, tem pressão alta, etc.
>- $u_i$ representa um vetor de covariáveis __não observadas__: variante de um gene, fator ambiental, etc.
>- $Z_i$ é o tratamento atribuído: tomou aspirina?
>    + $Z_i = 0$, se não tomou aspirina; $Z_i = 1$, se tomou aspirina.
>- Utilizaremos $\pi_i = \Pr (Z_i = 1)$ para designar a probabilidade do indivíduo $i$ ser atribuído ao grupo tratado (tomou aspirina).
>- $R_i$ é o desfecho/resposta: dor de cabeça sumiu?
>    + $R_i = 0$, se dor de cabeça não sumiu; $R_i = 1$, se dor de cabeça sumiu.

## Estrutura (continuação)

>- $r_{C_i}$ e $r_{T_i}$ representam os __desfechos potenciais__.
>    + $r_C$ é o desfecho que teria sido observado caso a aspirina NÃO tivesse sido tomada.
>    + $r_T$ é o desfecho que teria sido observado caso a aspirina tivesse sido tomada.
>- O par de desfechos potenciais $(r_{C_i}, r_{T_i})$ será descrito como o __efeito causal__ (individual).
>    + Chamaremos $\delta_i = r_{T_i} - r_{C_i}$ de o __efeito causal na escala da diferença__ (ou a __diferença do efeito causal__).
>    + Se $\delta_i = 0$ então o efeito causal é __nulo__; se $\delta_i \neq 0$ então existe um efeito causal (benéfico ou prejudicial).
>- Um destes desfechos potenciais é observado: se $Z = 0$, $r_C$ é observada; se $Z = 1$, $r_T$ é observada.
>    + Ou seja, $R_i = Z_i\times r_{T_i} + (1 - Z_i)\times r_{C_i}$.
>    + O outro é __contrafactual__.

## Estrutura: observações

1. Consideramos apenas dois níveis de tratamento por uma questão de simplicidade. Esta ideia pode ser generalizada para múltiplos níveis de tratamento e para outros regimes de tratamento mais gerais.
2. Em um __experimento aleatorizado__ $\pi_i = 1/2$.
3. Na estatística, a ideia de definir __efeitos causais__ como comparações de __desfechos potenciais__ foi introduzia por __Neyman__ no contexto de experimentos aleatorizados\footnote{Splawa-Neyman, J., Dabrowska, D.M., Speed, T.P. On the Application of Probability Theory to Agricultural Experiments. Essay on Principles. Section 9. \emph{Statistical Science} 5:465-472, 1990.}. Posteriormente, __Rubin__ generalizou esta ideia para o contexto de experimentos não-aleatorizados (estudos observacionais)\footnote{Rubin, D.B. Estimating causal effects of treatments in randomized and nonrandomized
studies. \emph{Journal of Educational Psychology} 66:688–701, 1974.}. Alguns autores se referem a esta abordagem como o __modelo causal de Rubin__\footnote{Holland, P. Statistics and Causal Inference. \emph{JASA}, 81:945-960, 1986.}.

## Estrutura: observações

4. Efeitos causais são comparações de desfechos potenciais sob tratamentos alternativos.
    - Para um indivíduo específico é perguntado: 
        + O que aconteceria com esse indivíduo sob o primeiro tratamento?
        + O que aconteceria com o indivíduo sob o segundo tratamento?
        + O indivíduo se sairia melhor sob o primeiro, em vez do segundo tratamento?
        + O desfecho seria o mesmo sob os dois tratamentos?
5. __Problema fundamental da inferência causal__\footnote{Holland, P. Statistics and Causal Inference. \emph{JASA}, 81:945-960, 1986.}: nós nunca vemos o efeito causal porque o efeito causal é a comparação de dois desfechos potenciais que o indivíduo teria exibido sob os dois tratamentos alternativos.
    - A inferência causal é difícil porque é sobre algo que nunca podemos ver.
6. Em verdade, $R_i = Z_i\times r_{T_i} + (1 - Z_i)\times r_{C_i}$ é __uma suposição__. Chamaremos esta __suposição de consistência__ (se $Z_i = 0 \Rightarrow R_i = r_{C_i}$, e se $Z_i = 1 \Rightarrow R_i = r_{T_i}$).

## Estrutura: observações

7. __Notações alternativas:__ o par de desfechos potenciais $(r_{C_i}, r_{T_i})$ muitas vezes é denotado por $(Y_i(0), Y_i(1))$.
8. No exemplo, o desfecho é dicotômico. Mas, o mesmo poderia ser um desfecho qualquer (discreto ou contínuo).
9. Alguns autores utilizam os termos "desfechos potenciais" e "variáveis contrafactuais" de forma alternada\footnote{VanderWeele, T. \emph{Explanation in Causal Inference: Methods for Mediation and Interaction}. Oxford University Press, 2015.}. Já outros autores fazem a distinção entre estes dois termos\footnote{Imbens, G. W., Rubin, D. B. \emph{Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction}. Cambridge University Press, 2015.}, pois no primeiro, antes da atribuição ao tratamento, os dois desfechos são possíveis (potenciais) de ocorrer, enquanto que o segundo se refere ao momento posterior a atribuição ao tratamento (fato e contrário ao fato).

## Desfechos potenciais no senso comum

\begin{block}{The Family Man (2000)}
\begin{columns}[c]
\column{1.3in}
\includegraphics[width=0.9\columnwidth]{TheFamilyMan}
\column{3.3in}
{\scriptsize Jack Campbell é um investidor de Wall Street jovem e solteiro vivendo uma vida de rico em Nova Iorque. Ele se surpreende quando sua ex-namorada, Kate, tentou ligar para ele após anos sem se verem. Após uma conversa com o seu mentor na empresa, Jack resolve pensar se responderia a esta chamada no dia seguinte. Naquela noite de Natal, porém, ele resolve ir a pé até sua casa, passando por uma loja de conveniências no caminho e convencendo para que um vencedor da loteria, irritado, chamado Cash, não atirasse no vendedor. Ele oferece ajuda à Cash antes de ir dormir em sua cobertura.}
\end{columns}
{\scriptsize Tudo muda num passe de mágica quando na manhã seguinte ele acorda em um quarto no subúrbio de Nova Jersey com Kate, a sua atual esposa, com quem anteriormente ele havia deixado de se casar e ainda com duas crianças que ele sequer conhecia. Jack percebe então que esta é justamente \structure{a vida que ele teria} se não tivesse se transformado em um investidor financeiro quando jovem. Ao invés disso, ele tem uma vida modesta, onde ele é um vendedor de pneus e Kate é uma advogada não-remunerada.}
\end{block}

## Desfechos potenciais no senso comum

\begin{block}{Rodrigo do violão}
\begin{columns}[c]
\column{2.3in}
\includegraphics[width=0.9\columnwidth]{vio}
\column{2.3in}
\includegraphics[width=0.9\columnwidth]{caminho_potencial}
\end{columns}
\end{block}

## O "mundo ideal"

|                       |       $r_C$        |       $r_T$        |
| :-------------------- | :----------------: | :----------------: |
| Mary                  |         0          |         0          |
| Anna                  |         1          |         0          |
| \textcolor{red}{Emma} | \textcolor{red}{0} | \textcolor{red}{1} |
| Elizabeth             |         0          |         0          |
| Minnie                |         1          |         1          |
| Margaret              |         0          |         0          |
| Ida                   |         0          |         0          |
| Alice                 |         0          |         0          |
| Bertha                |         1          |         0          |
| Sarah                 |         0          |         0          |
| Annie                 |         1          |         1          |
| Clara                 |         0          |         1          |

## O "mundo ideal"

Com o par de desfechos potenciais, podemos responder as seguintes perguntas:

- A aspirina causou o desaparecimento da dor de cabeça de Emma?
    - E de Margaret?
    - E de Clara?
    - E de Alice?

## O "mundo ideal"

| $i$       | $r_{C_i}$ | $r_{T_i}$ | $\delta_i = r_{T_i} - r_{C_i}\neq 0\ ?$ (existe efeito causal?) |
| :-------- | :-------: | :-------: | :------------------------------------------------------- |
| Mary      |     0     |     0     | $0$ (Não)                                                      |
| Anna      |     1     |     0     | $-1$ (Sim, prejudicial)                                         |
| Emma      |     0     |     1     | $1$ (Sim, benéfico)                                            |
| Elizabeth |     0     |     0     | $0$ (Não)                                                      |
| Minnie    |     1     |     1     | $0$ (Não)                                                      |
| Margaret  |     0     |     0     | $0$ (Não)                                                      |
| Ida       |     0     |     0     | $0$ (Não)                                                      |
| Alice     |     0     |     0     | $0$ (Não)                                                      |
| Bertha    |     1     |     0     | $-1$ (Sim, prejudicial)                                         |
| Sarah     |     0     |     0     | $0$ (Não)                                                      |
| Annie     |     1     |     1     | $0$ (Não)                                                      |
| Clara     |     0     |     1     | $1$ (Sim, benéfico)                                            |

## O mundo real!

| $i$       | $r_{C_i}$ | $r_{T_i}$ | $Z_i$ | $R_i$ |
| :-------- | :-------: | :-------: | :---: | :---: |
| Mary      |     0     |     \textcolor{red}{?}     |   0   |   0   |
| Anna      |     \textcolor{red}{?}     |     0     |   1   |   0   |
| Emma      |     \textcolor{red}{?}     |     1     |   1   |   1   |
| Elizabeth |     0     |     \textcolor{red}{?}     |   0   |   0   |
| Minnie    |     1     |     \textcolor{red}{?}     |   0   |   1   |
| Margaret  |     \textcolor{red}{?}     |     0     |   1   |   0   |
| Ida       |     \textcolor{red}{?}     |     0     |   1   |   0   |
| Alice     |     0     |     \textcolor{red}{?}     |   0   |   0   |
| Bertha    |     1     |     \textcolor{red}{?}     |   0   |   1   |
| Sarah     |     0     |     \textcolor{red}{?}     |   0   |   0   |
| Annie     |     1     |     \textcolor{red}{?}     |   0   |   1   |
| Clara     |     \textcolor{red}{?}     |     1     |   1   |   1   |

## O mundo real!

### O problema fundamental da inferência causal

- É impossível de se observar o valor de $r_{T_i}$ e $r_{C_i}$ na mesma unidade e, portanto, é impossível observar o efeito $\delta_i$.
- Um problema de __dados ausentes__.

## Efeitos causais populacionais

- $\delta_i = r_{T_i} - r_{C_i} =\color{red}{?}$, para todo indivíduo $i$, pois um dos desfechos potenciais nunca é observado.
- Um objetivo menos ambicioso é focar no __efeito causal médio__ (ou em nível populacional):

$$
\overline{\delta} = \E[r_{T_i} - r_{C_i}] = \E[r_{T_i}] - \E[r_{C_i}].
$$

- No caso em que a resposta é dicotômica, temos

$$
\overline{\delta} = \Pr(r_{T_i} = 1) - \Pr(r_{C_i} = 1).
$$

## Efeitos causais populacionais

\tiny

| $i$       | $r_{C_i}$ | $r_{T_i}$ | $\delta_i$ |
| :-------- | :-------: | :-------: | :--------- |
| Mary      |     0     |     0     | $0$        |
| Anna      |     1     |     0     | $-1$       |
| Emma      |     0     |     1     | $1$        |
| Elizabeth |     0     |     0     | $0$        |
| Minnie    |     1     |     1     | $0$        |
| Margaret  |     0     |     0     | $0$        |
| Ida       |     0     |     0     | $0$        |
| Alice     |     0     |     0     | $0$        |
| Bertha    |     1     |     0     | $-1$       |
| Sarah     |     0     |     0     | $0$        |
| Annie     |     1     |     1     | $0$        |
| Clara     |     0     |     1     | $1$        |
|           | $\E[r_{C_i}] = \Pr(r_{C_i} = 1) = 4/12$ | $\E[r_{T_i}] = \Pr(r_{T_i} = 1) = 4/12$ | $\overline{\delta} = 4/12 - 4/12 = 0$ |

\normalsize

- Ou seja, __não existe__ efeito causal em nível populacional.

## Efeitos causais populacionais

- Em verdade, __não sabemos__ $r_T$ para cada indivíduo, então __não podemos simplesmente estimar__ $\Pr(r_{T_i} = 1)$ como a proporção de todos os indivíduos com $r_T = 1$.
- Da mesma forma, __não podemos simplesmente estimar__ $\Pr(r_{C_i} = 1)$ como a proporção de todos os indivíduos com $r_C = 1$.
- Assim, __não podemos estimar__ facilmente $\overline{\delta} = \Pr(r_{T_i} = 1) - \Pr(r_{C_i} = 1)$ pelo mesmo motivo que não podemos estimar $\delta_i = r_{T_i} - r_{C_i}$.
- A inferência causal __é toda sobre a escolha de quantidades dos dados observados__ (isto é, envolvendo $Z$, $R$ e outras variáveis observadas) __que representam substitutos razoáveis__ para quantidades hipotéticas tais como $\overline{\delta}$, que envolvem contrafactuais não observáveis.

## Quando associção é igual a causalidade?

- O que pode ser um bom substituto para $\Pr(r_{T_i} = 1)$?
    + $\hat{r}_T = \Pr(R = 1 | Z = 1)$?
    + Esta é a proporção de "dor de cabeça que desapareceu" entre aquelas senhoras que realmente tomaram a aspirina.
    + Isso é o mesmo que $\Pr(r_{T_i} = 1)$?

### Ignorabilidade

- Somente se aquelas senhoras que tomaram a aspirina forem __intercambiáveis__ com aquelas que não o fizeram.
- Esta condição (suposição) é conhecida como __ignorabilidade da atribuição ao tratamento__ ($(r_C, r_T) \independent Z | X$, __ausência de confundimento__).
- Este seria o caso se a escolha de tomar a aspirina fosse feita __ao acaso__.
- É por isso que __experimentos aleatorizados__ são o __padrão-ouro__ para inferir efeitos causais.

## Quando associção é igual a causalidade?

| $i$       | $r_{C_i}$ | $r_{T_i}$ | $Z_i$ | $R_i$ |
| :-------- | :-------: | :-------: | :---: | :---: |
| Mary      |     0     |     \textcolor{red}{?}     |   0   |   0   |
| Elizabeth |     0     |     \textcolor{red}{?}     |   0   |   0   |
| Minnie    |     1     |     \textcolor{red}{?}     |   0   |   1   |
| Alice     |     0     |     \textcolor{red}{?}     |   0   |   0   |
| Bertha    |     1     |     \textcolor{red}{?}     |   0   |   1   |
| Sarah     |     0     |     \textcolor{red}{?}     |   0   |   0   |
| Annie     |     1     |     \textcolor{red}{?}     |   0   |   1   |
|      |          |          |      |   $\hat{r}_C = \Pr(R = 1 | Z = 0) = 3/7$   |

## Quando associção é igual a causalidade?

| $i$       | $r_{C_i}$ | $r_{T_i}$ | $Z_i$ | $R_i$ |
| :-------- | :-------: | :-------: | :---: | :---: |
| Anna      |     \textcolor{red}{?}     |     0     |   1   |   0   |
| Emma      |     \textcolor{red}{?}     |     1     |   1   |   1   |
| Margaret  |     \textcolor{red}{?}     |     0     |   1   |   0   |
| Ida       |     \textcolor{red}{?}     |     0     |   1   |   0   |
| Clara     |     \textcolor{red}{?}     |     1     |   1   |   1   |
|      |          |          |      |   $\hat{r}_T = \Pr(R = 1 | Z = 1) = 2/5$   |

## Quando associção é igual a causalidade?

- Portanto,

$$
\hat{\delta} = \Pr(R = 1 | Z = 1) - \Pr(R = 1 | Z = 0) = \frac{2}{5} - \frac{3}{7} = - \frac{1}{35}.
$$

- Se assumirmos "associação = causalidade", concluiremos que __existe efeito causal__ e que a aspirina foi, em média, prejudicial.
- __Teste exato de Fisher:__ a "base racional para inferência" ($H_0: \delta_i = 0, i = 1, \ldots, I$).
    + No capítulo 2 de seu __Design of Experiments__, Fisher falou da aleatorização em experimentos como a __"base racional da inferência"__ nos experimentos.

## Mas, e se ...

... as senhoras com uma dor de cabeça __mais forte__ (grave) fossem __mais propensas__ a tomarem a aspirina?

- Neste caso, "associação $\neq$ causalidade"! Ou $(r_C, r_T) \notindependent Z | X$.

## Levando em conta a gravidade

- Suponha que perguntamos a cada uma das 12 senhoras no início do estudo: __"sua dor de cabeça é forte?"__.
    + Então, poderíamos propor que, depois de levar em conta a gravidade, a decisão de tomar ou não a aspirina fosse efetivamente tomada de forma aleatória.
- Suponha que $X$ denota a gravidade. Então, sob essa suposição, __dentro dos estratos__ de $X$, os indivíduos expostos e não expostos podem ser __intercambiáveis__.
- Isso é chamado de __intercambiabilidade (permutabilidade) condicional__ (dado $X$).
- Sob intercambiabilidade condicional dada $X$, "associação = causalidade" __dentro dos estratos__ de $X$.

## Levando em conta a gravidade


| $i$       | $r_{C_i}$ | $r_{T_i}$ | $Z_i$ | $R_i$ | $X_i$ |
| :-------- | :-------: | :-------: | :---: | :---: | :---: |
| Mary      |     0     |     0     |   0   |   0   |   1   |
| Anna      |     1     |     0     |   1   |   0   |   0   |
| Emma      |     0     |     1     |   1   |   1   |   0   |
| Elizabeth |     0     |     0     |   0   |   0   |   1   |
| Minnie    |     1     |     1     |   0   |   1   |   0   |
| Margaret  |     0     |     0     |   1   |   0   |   1   |
| Ida       |     0     |     0     |   1   |   0   |   1   |
| Alice     |     0     |     0     |   0   |   0   |   0   |
| Bertha    |     1     |     0     |   0   |   1   |   1   |
| Sarah     |     0     |     0     |   0   |   0   |   0   |
| Annie     |     1     |     1     |   0   |   1   |   0   |
| Clara     |     0     |     1     |   1   |   1   |   1   |

## Estratificando por gravidade

No estrato $X = 0$:

- $\hat{r}_T = \Pr(R = 1 | Z = 1) = 1/2$ e $\hat{r}_C = \Pr(R = 1 | Z = 0) = 2/4$, e portanto,

$$
\hat{\delta} = \hat{r}_T - \hat{r}_C = \frac{1}{2} - \frac{2}{4} = 0.
$$

No estrato $X = 1$:

- $\hat{r}_T = \Pr(R = 1 | Z = 1) = 1/3$ e $\hat{r}_C = \Pr(R = 1 | Z = 0) = 1/3$, e portanto,

$$
\hat{\delta} = \hat{r}_T - \hat{r}_C = \frac{1}{3} - \frac{1}{3} = 0.
$$

- Ou seja, dentro dos estratos __não existe__ efeito causal.

## Exemplo da dor de cabeça: breves conclusões

- De maneira mais geral, se __existe__ um efeito causal de $Z$ em $R$, mas também __uma associação não-causal__ devido a $X$, então o efeito causal será estimado com __viés__, a menos que estratifiquemos em $X$.
    + Este viés será chamada de __viés de confundimento__ (ou viés de confusão) e $X$ será chamada de __variável confundidora__.

## Exemplo da dor de cabeça: breves conclusões

- A __intercambiabilidade condicional__ é o principal critério que nos permite fazer declarações causais usando __dados observacionais__.
- Assim, precisamos identificar, se possível, um conjunto de (co)variáveis $X_1, X_2, \ldots$ , de tal forma que a intercambiabilidade condicional é válida, dado este conjunto de variáveis.
- Na vida real, pode haver muitas variáveis candidatas $X$.
- Estes podem ser __causalmente inter-relacionados__ de uma maneira __muito complexa__.
- Decidir se os indivíduos expostos e o não expostos são  condicionalmente intercambiáveis, dado $X_1, X_2, \ldots$, __requer conhecimento detalhado do assunto__.
- Os __diagramas causais__ (DAGs) podem nos ajudar a usar esse conhecimento para determinar se a intercambiabilidade condicional é válida ou não (critério _back-door_, variáveis não observadas).

## DAGs: um exemplo

\begin{columns}
\begin{column}{.5\linewidth}
```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, out.width='60%', paged.print=FALSE}

knitr::include_graphics(here('images', 'terminologia1.png'))

```
\end{column}
\begin{column}{.5\linewidth}
\begin{block}{Grafo acíclico dirigido}
\begin{itemize}
\item Este é um exemplo de um \structure{grafo acíclico dirigido} (DAG) causal (diagrama causal).
\item É \structure{dirigido}, pois cada aresta é uma seta de ponta única.
\item É \structure{causal}, pois as setas representam nossas suposições a respeito da direção da influência causal.
\item É \structure{acíclico}, pois não contém ciclos: nenhuma variável causa a si mesma.
\end{itemize}
\end{block}
\end{column}
\end{columns}

## Métodos de estimação

- Suponha que, aplicando o critério \emph{back-door}, nosso diagrama causal nos diga que o conjunto $X = \{X_1, X_2, \ldots, X_p\}$ \structure{(sexo, idade, gravidade da dor, uso de álcool, ...)} é suficiente para controlar para confusão.
- \structure{Como} analisamos os dados para estimarmos o efeito causal médio da exposição (ou tratamento, o $\bar{\delta}$)?
    + Estratificação.
    + Ajuste por covariável na análise de regressão.
    + Escore de propensão.
    + Pareamento.
    + Ponderação.

## Métodos de estimação: estratificação {.allowframebreaks}

- Se o número de covariáveis de ajuste é pequeno e estes são categóricos/dicotômicos, podemos criar \structure{estratos} com base nestas covariáveis.
- Em seguida, calculamos o efeito de interesse em cada estrato e então \structure{combinamos} os resultados (ajuste direto e Mantel-Haenszel).

\framebreak

\begin{eqnarray*}
\bar{\delta} &=& \bar{r}_T - \bar{r}_C \\
&=& \E[r_{T_i}] - \E[r_{C_i}] \\
&=& \E[\E[r_{T_i}|X_i]] - \E[\E[r_{C_i}|X_i]] \\
&=& \E[\E[r_{T_i}|Z_i = 1, X_i]] - \E[\E[r_{C_i}|Z_i = 0, X_i]] \\
&=& \E[\E[R_i|Z_i = 1, X_i]] - \E[\E[R_i|Z_i = 0, X_i]] \\
&=& \E[\E[R_i|Z_i = 1, X_i] - \E[R_i|Z_i = 0, X_i]] \\
&=& \sum_x{(\E[R_i|Z_i = 1, X_i = x] - \E[R_i|Z_i = 0, X_i = x])\Pr(X_i = x)}.
\end{eqnarray*}

## Métodos de estimação: estratificação

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, out.width='90%', out.height='80%', paged.print=FALSE, purl=FALSE}

knitr::include_graphics(here::here('images', 'table_5_6.png'))

```

## Métodos de estimação: regressão

- Se o nosso conjunto suficiente para controle de confusão contém muitos confundidores (e possivelmente contínuos), teremos muitos e pequenos estratos, perdendo precisão nas estimativas.
- Uma alternativa natural é ajustar para $X$ em um \structure{modelo de regressão}.
    + Desenhe o DAG
    + Identifique o conjunto suficiente de confundidores $X$
    + Inclua estes confundidores __apropriadamente__ em um modelo de regressão
        - É importante avaliar relações não-lineares, termos de interação, suposições distribucionais, etc.

## Métodos de estimação: regressão {.allowframebreaks}

- Considere o caso em que $R$, a variável resposta/desfecho, seja contínua.
- O modelo de regressão linear supõe:
$$
\E[R|Z = z, X_1, \ldots, X_p] = \beta_0 + \beta_Zz + \beta_1x_1 + \ldots + \beta_pX_p.
$$

- Assim,

\begin{eqnarray*}
\hat{\delta} &=& \frac{1}{n}\sum_{i=1}^n{\left\{ \hat{\E}[R_i|Z_i = 1, x_1, \ldots, x_p] - \hat{\E}[R_i|Z_i = 0, x_1, \ldots, x_p]\right\}}\\
& = & \frac{1}{n}\sum_{i=1}^n{\left\{(\hat{\beta}_0 + \hat{\beta}_Z + \sum_{k=1}^p{\hat{\beta}_kx_{ik}}) - (\hat{\beta}_0 + \sum_{k=1}^p{\hat{\beta}_kx_{ik}})\right\}}\\
& = & \frac{1}{n}\sum_{i=1}^n{\left\{\hat{\beta}_Z\right\}} = \frac{1}{n} \times n\hat{\beta}_Z = \hat{\beta}_Z.
\end{eqnarray*}

\framebreak

Se

1. o conjunto suficiente de confundidores $Z$ foi corretamente selecionado a partir do DAG corretamente especificado;
2. o modelo de regressão foi corretamente especificado;

então pode ser dada uma interpretação causal a $\hat{\beta}_Z$.

- __Intervalos de confiança__ e __testes de hipóteses__ podem ser cosntruídos a partir das propriedades de $\hat{\beta}_Z$.

\framebreak

- Agora, suponha que $R$, a variável resposta/desfecho, seja dicotômica.
- O modelo de regressão logísitica (uma possibilidade de modelo para uma variável resposta dicotômica) supõe:

\begin{eqnarray*}
\E[R|Z=z,X_1,\ldots,X_p] &=& \Pr[R=1|Z=z,X_1,\ldots,X_p]\\
&=& \frac{\exp\{\beta_0 + \beta_Zz + \sum_{k=1}^p{\beta_kx_{k}}\}}{1 + \exp\{\beta_0 + \beta_Zz + \sum_{k=1}^p{\beta_kx_{k}}\}}.
\end{eqnarray*}

\framebreak

- Assim,

\footnotesize
\begin{eqnarray*}
\hat{\delta} &=& \frac{1}{n}\sum_{i=1}^n{\left\{\hat{\E}[R_i|Z_i = 1, x_1, \ldots, x_p] - \hat{\E}[R_i|Z_i = 0, x_1, \ldots, x_p]\right\}}\\
&=& \frac{1}{n}\sum_{i=1}^n{\left\{\hat{\Pr}[R=1|Z=1,X_1,\ldots,X_p] - \hat{\Pr}[R=1|Z=0,X_1,\ldots,X_p]\right\}}\\
&=& \frac{1}{n}\sum_{i=1}^n{\left\{\frac{\exp\{\hat{\beta}_0 + \hat{\beta}_Z + \sum_{k=1}^p{\hat{\beta}_kx_{k}}\}}{1 + \exp\{\hat{\beta}_0 + \hat{\beta}_Z + \sum_{k=1}^p{\hat{\beta}_kx_{k}}\}} - \frac{\exp\{\hat{\beta}_0 + \sum_{k=1}^p{\hat{\beta}_kx_{k}}\}}{1 + \exp\{\hat{\beta}_0 + \sum_{k=1}^p{\hat{\beta}_kx_{k}}\}}\right\}}.
\end{eqnarray*}

\normalsize

\framebreak

- \structure{Observação:} fora do modelo linear, $\hat{\beta}_Z$ não é a estimativa do $\delta$.
\item Métodos de reamostragem (por exemplo, o \structure{\emph{bootstrap}}) podem ser utilizados na construção de intervalos de confiança e testes de hipóteses para o $\delta$.

## Métodos de estimação: o escore de propensão {.allowframebreaks}

- No caso em que o conjunto suficiente possui muitos confundidores, o ajuste destes confundidores na análise de regressão pode implicar na falta de precisão das estimativas.
- Uma alternativa é ajustar por uma função (resumo) dos confundidores, por exemplo, o \structure{escore de propensão}.
- O escore de propensão $p(X)$ é a probabilidade condicional de $Z=1$ dado $X=(X_1,\ldots,X_p)$

$$
p(X) = \Pr(Z=1|X).
$$

\framebreak

- $p(X)$ é um escalar, independentemente da dimensão de $X$.
- $p(X)$ pode ser estimado por regressão logística.
    + Abordagens mais modernas têm utilizado métodos de \structure{aprendizagem de máquina} para estimar $p(X)$.
- \structure{Intuição:} Se dois indivíduos, um exposto e outro não-exposto, têm o mesmo valor do escore de propensão, $0,25$, por exemplo, são igualmente propensas a serem expostas (receberem o tratamento).
- \structure{Resultado teórico:} intercambiabilidade condicional dado $p(X)$.

\framebreak

- Existem diferentes maneiras de incorporar o escore de propensão na análise para a estimação do efeito causal de interesse:
    1. estratificação (faixas do escore de propensão como estratos)
    2. ajuste na regressão (no lugar dos confundidores, se utiliza apenas o escore de propensão)
    3. pareamento (esocore de propensão como uma medida de distância entre indivíduos)
    4. ponderação (o inverso do escore de propensão como uma ponderação).
- Estes métodos são válidos somente se os confundidores corretos $X$ são incluídos no conjunto de ajuste e se $p(X)$ é modelado corretamente.

## Métodos de estimação: pareamento {.allowframebreaks}

- \structure{Métodos de pareamento:} controlam os confundidores por uma etapa pré-análise.
    + Encontram pares de indivíduos (um exposto e um não-exposto) \structure{similares} com respeito aos confundidores.
    + Métricas (distâncias) são utilizadas para estabelecer a similaridade entre indivíduos.
    + O escore de propensão pode ser utilizado como medida de similaridade, assim como a distância Euclidiana, ou a distância de Mahalanobis.

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, out.width='90%', out.height='80%', paged.print=FALSE, purl=FALSE}

knitr::include_graphics(here::here('images', 'pareamento.png'))

```

## Comentários finais

- Nesta introdução apresentamos os conceitos básicos da abordagem de desfechos potenciais para inferência causal.
    + Definição dos efeitos causais.
    + Identificação dos efeitos causais.
    + Estimação dos efeitos causais.
- __O que vem depois?__
    + Análise de sensibilidade.
    + Análise de mediação: decomposição do efeito total em efeitos direto e indireto.
    + Análise de interação: modificação do efeito.
    + Confundidores intermediários.
    + Confundidores tempo-dependentes.
    + Desfechos: tempo até evento; séries temporais; dados longituinais.

## Muito obrigado!

```{r echo=FALSE, fig.align='center', message=FALSE, warning=FALSE, out.width='100%', out.width='80%', paged.print=FALSE, purl=FALSE}

knitr::include_graphics(here('images', 'caffeine-causality-loop.jpg'))

```

